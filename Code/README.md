# 마스크 착용 상태 분류

  
### 데이터 전처리

  
1. CLAHE 기법 사용

 모델이 피부의 주름을 잘 식별하게 하기 위해 화질의 선명도를 개선할 필요성을 느끼고 CLAHE 기법을 사용했다. 해당 작업을 통해 CLAHE 기법을 사용하기 전보다 3% 가량의 정확도 향상을 이루어냈다.

  
2. CenterCrop

 테스트 데이터를 가시화한 결과, 꽃무늬 마스크를 한 남자를 여자로 인식하는 현상들이 발생했다.

 이러한 결과가 발생한 이유를 모델이 옷의 특징까지 고려했음이라 판단했고, 얼굴만 따로 자르기로 결정했다.
 
 원래는 이전에 사용한 경험이 있는 AWS Rekognition를 사용할까 생각해보았으나, 사용량과 학습 시간이 길어질 것을 생각했을 때 좋지 않은 아이디어일 것이라고 생각했다.
 
 대신 모든 사진이 공통된 크기와 위치를 가지고 있는 점을 고려하여 CenterCrop을 수행했고, 여러 실험 결과 350, 350이 가장 얼굴만을 Crop했고, 이를 토대로 CenterCrop을 수행했다. 그리고 정확도가 약간 상승했다.

  
3. 나이대 수정

 기존의 목표는 60대 이상을 별도로 식별하는 것이었으나, 모델이 60세 이상을 잘 식별하지 못함을 발견했다. 그래서 라벨링을 60이상이 아니라 58이상으로 설정하고 실험을 진행했다. 그리고 연령대를 보다 잘 예측하여 정확도가 향상됨을 확인했다.

 57, 59 도 실험을 해보려고 했으나, 마침 토론에서 한 캠퍼분께서 58로 설정하면 좋은 결과가 나온다는 언급을 해주셨고, 이를 믿고 별도로 실험을 진행하지 않았다.

  
4. Sharpen

 이미지를 보다 선명하기 위해 사용했다. 일반 이미지로 할 때보다 좋은 성능이 나왔지만, CLAHE 기법에 비할 바가 되지 못했다.

 CLAHE와 Sharpen을 섞어서도 사용해보았지만 마찬가지로 CLAHE보다 못한 결과를 보였다.

  
5. Own_Image, CLAHE_Image, Sharpen_Image

 데이터 수를 증가시키기 위해 모든 학습 데이터를 원본 이미지, CLAHE 적용 이미지, Sharpen 이미지로 나누어 실험을 진행해보았다. 작업 시간이 몇 배로 늘어났고, 정확도는 크게 떨어졌다.

  
### 데이터 전처리_아쉬운 점

  
1. 데이터 증강 미사용

 학습 이미지와 검증 이미지가 형식이 완전히 똑같았다. 필터를 사용하지도, 각도를 기울이지도 않았다.

 만약 모델을 현실에서 사용하고자 했다면 이러한 점들을 전부 고려하여 데이터 증강을 하는 것이 맞다. 하지만 ‘똑같은 형식의 학습 셋으로 학습해서, 똑같은 형식의 검증 셋을 검증하는데 굳이 데이터 증강을 활용해야 할까?’ 라는 생각이 들었다. 오히려 데이터가 섞임으로써 정확도가 낮아질 수도 있을 것이라는 생각이 들었다. 그래서 데이터 증강을 진행하지 않았다.

 그러나 데이터 증강으로 인하여 정확도가 크게 향상한 다른 캠퍼분들의 사례를 듣고, 뒤늦게 데이터 증강을 시도해보았다. 비록 미미한 수준이었으나 정확도가 향상했다. 하지만 너무 늦게 시도를 한 탓에 시간이 없어 더 다양한 시도를 해보지 못했다. 아마 일찍 데이터 증강을 시도했다면 더 많은 기법들을 적용해보고 실험해보며 정확도를 향상시킬 수 있었을 것이라는 아쉬움이 남았다.

  
### 모델 구성

  
1. 3-Label Model

 지금까지 많은 인공지능을 만들어보진 못했지만, 모든 인공지능들의 목표는 한 개의 특징을 식별하는 것이었다. 하지만 이번 과제는 세 개의 특징을 식별해야 하는 것이었고, 이에 따라 첫 날에는 마스크 착용 여부, 성별, 연령대를 식별하는 세 개의 별도의 모델을 만들려고 했다. 토론 게시판을 보니 많은 분들께서 같은 생각을 하신 것 같다.

 하지만 곰곰이 생각을 해보니 굳이 그럴 필요가 딱히 없을 것 같았다. 비록 세 개의 특징을 식별한다고는 하나, 최종적으로 라벨 수는 18개이고, 이는 ImageNet과 같은 대형 데이터의 라벨 수에 미치지 못하는 숫자였다.

 그렇기에 비록 특징은 세 개이나, 라벨 수로 봤을 때는 그렇게 큰 데이터셋이 아니라는 생각이 들었고, 세 개의 모델이 아닌 하나의 모델을 사용하기로 결정했다.

  
2. ResNet, DenseNet

 각자 층이 다른 ResNet 세 개와, DenseNet 두 개를 학습시켰다. 그리고 각 모델들의 결과물들을 Soft Vote 형식으로 앙상블하여 결과를 유추했다. 학습 결과는 60 후반에서 70 초반으로 나왔다.

  
3. EfficientNet

 ResNet과 DenseNet으로 계속해서 시도를 했으나, 어떤 시도에도 70 초반을 벗어날 생각을 하지 않았다. 그래서 어떻게 할까 생각을 하던 중, 이미 다른 캠퍼분들께서는 EfficientNet을 사용 중이고, 다른 모델에 비해 월등한 성능을 자랑한다는 이야기를 들었다.

 그래서 곧바로 EfficientNet을 찾아 사용하기 시작했다. efficientnet-b7, efficientnet-b6, efficientnet-b5, efficientnet-b4, efficientnet-b3 총 다섯 개의 모델을 빌려왔고, 각자 학습을 진행한 후 결과물들을 Soft Vote 하여 결과를 출력했다.

 EfficientNet은 단일 모델로도 위의 ResNet과 DenseNet의 앙상블보다 더 좋은 효과를 냈다. 비록 금방 과적합하기는 했지만, 이는 Early Stop을 걸어준 후 원하는 정확도가 나오면 곧바로 학습을 종료함으로써 해결했다.

 Early Stop 정확도는 0.95~0.99 까지 각자 진행해보았고, 0.99의 경우에는 과적합하여 오히려 성능이 내려가고 0.97과 0.98이 가장 좋은 성능을 보였다.


### 모델 구성_아쉬운 점

  
1. Accuracy와 CrossEntropyLoss의 고집

 이번 컴피티션의 최종 스코어는 F1-Score을 기반으로 한다. 그렇기에 다른 캠퍼분들께서는 이미 F1 Score를 사용하셨다.

 하지만 나는 끝까지 Acc와 크로스엔트로피를 고집했다. 이유라면 잘못된 고집 때문이었던 것 같다.

 Acc나 F1-Score나 결국은 모델이 데이터를 얼마나 잘 예측하는 지 보여주는 지표이다. 그렇기에 비록 계산 방식은 다를 지언정 당연히 모델의 성능이 좋다면, 두 지표 역시 높을 수밖에 없을 것이라는 생각이 들었다.

 그래서 굳이 F1-Score를 사용하지 않았다. 계속 acc를 고집하며, 손실함수 등에 신경을 쓸 시간에 데이터 전처리와 검증을 어떻게 할까에 할애했다. F1-Score를 활용해 정확도를 보며 모델을 구축했다면 더 좋은 모델을 학습시킬 수 있지 않았을까? 하는 아쉬움이 남는다.

  
2. 검증 데이터 미사용

 인공지능을 처음 가르쳐주셨던 교수님께서는 ‘아무리 간단한 모델이라도 제대로 동작하려면 최소 10만개 이상의 데이터는 필요하다’는 말씀을 해주셨다.

 이번 컴피티션의 학습 데이터는 2만 개가 되지 못한다. 위의 이유로 별도로 증강 기법을 사용하지 않았기에 데이터를 늘리지도 않았다. 그래서 2만개도 되지 않는 데이터를 검증 셋으로 또다시 분리하는 것이 너무 아까웠다.

 물론 K-Fold를 사용하여 여러 개의 모델을 만들어 앙상블을 시키는 방법도 있었지만, 이미 하나의 모델을 여러 개로 나누어 학습 시키는 것보다, 여러 개의 모델을 앙상블 하는 방법을 선택했기에 K-Fold에도 별로 미련이 없었다.

 또한 모델을 학습시키는 데 늘 한나절이 걸렸다. 그래서 아침에 일어나서 제출하고, 밤에 자기 전에 제출하는 것이 일상이었다. 이 덕분에 10번의 제출 제한이 전혀 부족하지 않았고, 제출을 통해 얻은 결과로 검증을 시도했기에 검증 데이터가 별도로 필요하지 않았다.

 하지만 K-Fold를 사용했다면 다른 결과가 나오지 않았을까? 하는 아쉬움이 남는다.

  
### 검증 전략

  
1. b5, 6, 7, b4, 5, 6, 7, b3, 4, 5, 6, 7

 EfficientNet_b5, 6, 7 의 성능은 훌륭했다. 하지만 3~4는 그렇지 않았다. 그래서 5, 6, 7 / 4, 5, 6, 7 / 3, 4, 5, 6, 7 으로 앙상블하여 세 개의 검증을 시도했다. 대부분의 경우 4,5,6, 7인 네 개의 모델이 가장 성능이 높았고, 5, 6, 7이 그 다음이었고, 3, 4, 5, 6, 7은 대부분의 경우 다른 결과들보다 성능이 낮았다.

  
2. 원본 이미지, CLAHE 별도 검증

 원본 이미지와 CLAHE 기법을 적용한 이미지, 두 개의 이미지로 검증을 시도했다. CLAHE 기법을 적용한 이미지를 학습한 모델들인 탓에 원본 이미지에 대한 검증 결과는 그렇게 좋지 못했고, CLAHE 기법을 사용해 검증하는 것이 훨씬 나은 정확도를 보였다.

  
### 검증 전략_아쉬운 점

  
1. Five-Crop

 이전에 Ten-Crop을 활용한 검증을 한 적이 있어, 어렵지 않게 할 수 있을 것이라 생각했다. 하지만 이상한 에러가 발생했고, 아무리 정보를 검색해도 해결되지 않았다. 개인적으로 torchvision 버전의 문제일 것이라고 유추하지만, 멋대로 버전을 바꾸었다가 GPU와 맞지 않는 버전이 될 수 있다는 생각이 들었다. 개인 컴퓨터가 아닌 서버의 환경을 멋대로 변경하고 싶지 않았고, 결국 포기했다.
